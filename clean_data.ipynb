{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "foreign-advance",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dying-financing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from autocorrect import Speller\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organized-danger",
   "metadata": {},
   "source": [
    "# Load raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simple-smooth",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = pd.read_csv(\"data/edited_data.csv\")\n",
    "raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radio-toner",
   "metadata": {},
   "source": [
    "# Adjust columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pursuant-electric",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unnamed columns\n",
    "df = raw.loc[:, ~raw.columns.str.contains('^Unnamed')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "miniature-refrigerator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename some columns\n",
    "df = df.rename(columns={\"Experience Tags\":\"Experience\",\"Can Help With\":\"Skills\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acute-disney",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# combine bio columns into one large column\n",
    "df = df.rename(columns={\"Bio\":\"Bio 1\"})\n",
    "bios = []\n",
    "for idx,row in df.iterrows():\n",
    "    full_bio = \"\".join([row[f\"Bio {i}\"] for i in range(1,9) if isinstance(row[f\"Bio {i}\"],str) and row[f\"Bio {i}\"]!=\"NaN\"])\n",
    "    bios.append(full_bio)\n",
    "df = df.drop(columns=[f\"Bio {i}\" for i in range(1,9)])\n",
    "df[\"Bio\"] = bios\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worth-popularity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove any duplicates\n",
    "users = []\n",
    "for idx, row in df.iterrows():\n",
    "    user = row[\"Name\"]\n",
    "    if user in users:\n",
    "        df = df.drop(idx)\n",
    "        print(f\"deleting duplicate of {user}\")\n",
    "    users.append(user)\n",
    "df = df.reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "guided-malaysia",
   "metadata": {},
   "source": [
    "# Parse keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polish-jordan",
   "metadata": {},
   "outputs": [],
   "source": [
    "experience_tags = [\n",
    "    \"Enterprise\",\n",
    "    \"Healthcare\",\n",
    "    \"Marketplace\",\n",
    "    \"Academia\",\n",
    "    \"Analytics\",\n",
    "    \"Biotech\",\n",
    "    \"Ecommerce\",\n",
    "    \"FinTech\",\n",
    "    \"Future of Work\",\n",
    "    \"Future of Food\",\n",
    "    \"Insurance\",\n",
    "    \"Science\",\n",
    "    \"Blockchain/Crypto\",\n",
    "    \"Direct to Consumer\",\n",
    "    \"Consumer\",\n",
    "    \"AI/ML\",\n",
    "    \"B2B\",\n",
    "    \"Climate\",\n",
    "    \"Community\",\n",
    "    \"Government\",\n",
    "    \"SaaS\",\n",
    "    \"Ecommerce\",\n",
    "    \"Coaching\",\n",
    "    \"Developer Tools\",\n",
    "    \"Clean Technology\",\n",
    "    \"IOT\",\n",
    "    \"Productivity\",\n",
    "    \"Real Estate\",\n",
    "    \"Social\",\n",
    "    \"Mental Health/Wellness\",\n",
    "    \"Talent\",\n",
    "    \"Hardware\",\n",
    "    \"Education\",\n",
    "    \"No-Code\",\n",
    "    \"Gaming\",\n",
    "    \"Transportation & Travel\",\n",
    "    \"Venture\",\n",
    "    \"Robotics\",\n",
    "    \"People Ops\",\n",
    "    \"VR/AR\",\n",
    "    \"Drones\",\n",
    "    \"Security\",\n",
    "    \"Legal\",\n",
    "    \"Social Impact\",\n",
    "    \"Construction\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nominated-reality",
   "metadata": {},
   "outputs": [],
   "source": [
    "skill_tags = [\n",
    "    \"Software Engineering\",\n",
    "    \"Business Development\",\n",
    "    \"Product Management\",\n",
    "    \"Research\",\n",
    "    \"Communications\",\n",
    "    \"Data Science\",\n",
    "    \"Operations\",\n",
    "    \"Growth\",\n",
    "    \"Analytics\",\n",
    "    \"Marketing\",\n",
    "    \"Product Management\",\n",
    "    \"Recruiting\",\n",
    "    \"C-Suite Executives\",\n",
    "    \"Sales\",\n",
    "    \"Design\",\n",
    "    \"Customer Service\",\n",
    "    \"Finance\",\n",
    "    \"Hardware Engineering\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "widespread-ocean",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_tags = [\n",
    "    \"Open to new ideas\",\n",
    "    \"In early stages of exploring a specific idea\",\n",
    "    \"Raising funding\",\n",
    "    \"Built a basic prototype/MVP\",\n",
    "    \"Starting to onboard customers\",\n",
    "    \"Seed+\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precious-procedure",
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_tags = [\n",
    "    \"Looking for co-founder\",\n",
    "    \"Looking to join another team\",\n",
    "    \"Looking for first employees\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "isolated-bailey",
   "metadata": {},
   "outputs": [],
   "source": [
    "interest_tags = experience_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increasing-trouble",
   "metadata": {},
   "outputs": [],
   "source": [
    "looking_for_tags = skill_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empirical-beaver",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tags = {\n",
    "    \"Experience\": experience_tags,\n",
    "    \"Skills\": skill_tags,\n",
    "    \"Stages\": stage_tags,\n",
    "    \"Objectives\": objective_tags,\n",
    "    \"Interests\": interest_tags,\n",
    "    \"Looking for\": looking_for_tags\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advance-albania",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into tokens/phrases\n",
    "cols_to_parse = [\"Experience\", \"Skills\", \"Stages\", \"Objectives\", \"Interests\", \"Looking for\"]\n",
    "for idx, row in df.iterrows():\n",
    "    for col in cols_to_parse:\n",
    "        try:\n",
    "            if isinstance(row[col],str) and row[col] != \"NaN\":\n",
    "                row[col] = list(np.unique([tag for tag in all_tags[col] if tag in row[col]]))\n",
    "        except:\n",
    "            print(f\"error in row {idx}, column {col}\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becoming-interview",
   "metadata": {},
   "source": [
    "# Save cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cheap-scientist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast everything as strings\n",
    "df = df.replace(np.nan, \"NaN\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neural-configuration",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/clean_data.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complimentary-spider",
   "metadata": {},
   "source": [
    "# Save all responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "irish-latter",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parental-assistant",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_include = [\"Experience\",\"Skills\",\"Interests\",\"Stages\",\"Objectives\",\"Looking for\"]\n",
    "all_responses = {\"Name\":[],\"Category\":[],\"Response\":[]}\n",
    "for idx,row in df.iterrows():\n",
    "    name = row[\"Name\"]\n",
    "    for col in cols_to_include:\n",
    "        if row[col] != \"nan\" and row[col] != \"NaN\":\n",
    "            responses = literal_eval(row[col])\n",
    "            for resp in responses:\n",
    "                all_responses[\"Name\"].append(name)\n",
    "                all_responses[\"Category\"].append(col)\n",
    "                all_responses[\"Response\"].append(resp)\n",
    "all_responses = pd.DataFrame.from_dict(all_responses)\n",
    "all_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worse-stick",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_responses.to_csv(\"data/response_data.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlikely-encoding",
   "metadata": {},
   "source": [
    "# Replace phrases with keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polar-bench",
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_map = {\n",
    "    \"Open to new ideas\": \"ideas\",\n",
    "    \"In early stages of exploring a specific idea\": \"exploring\",\n",
    "    \"Raising funding\": \"funding\",\n",
    "    \"Built a basic prototype/MVP\": \"prototype\",\n",
    "    \"Starting to onboard customers\": \"customers\",\n",
    "    \"Seed+\": \"seed\",\n",
    "    \"Looking for co-founder\": \"partner\",\n",
    "    \"Looking to join another team\": \"team\",\n",
    "    \"Looking for first employees\": \"employees\"\n",
    "}\n",
    "\n",
    "cols = [\"Stages\",\"Objectives\"]\n",
    "for idx, row in df.iterrows():\n",
    "    for col in cols:\n",
    "        try:\n",
    "            if isinstance(row[col],str) and row[col] != \"nan\" and row[col] != \"NaN\":\n",
    "                row[col] = [phrase_map[tag] if tag in phrase_map else tag for tag in literal_eval(row[col])]\n",
    "        except:\n",
    "            print(f\"error in row {idx}, column {col}\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mechanical-ballet",
   "metadata": {},
   "source": [
    "# Convert/remove acronyms/jargon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "future-meeting",
   "metadata": {},
   "outputs": [],
   "source": [
    "jargon_map = {\n",
    "    \"AI\": \"Artificial Intelligence\",\n",
    "    \"ML\": \"Machine Learning\",\n",
    "    \"B2B\": \"Business to Business\",\n",
    "    \"SaaS\": \"Software as a Service\",\n",
    "    \"FinTech\": \"Financial Technology\",\n",
    "    \"Biotech\": \"Biotechnology\",\n",
    "    \"Crypto\": \"Cryptocurrency\",\n",
    "    \"Ops\": \"Operations\",\n",
    "    \"VR/AR\": \"Virtual Reality and Artificial Reality\",\n",
    "    \"IOT\": \"Internet of Things\",\n",
    "    \"MVP\": \"minimum viable product\",\n",
    "    \"C-Suite\": \"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amateur-drill",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx, row in df.iterrows():\n",
    "    for col in cols_to_parse:\n",
    "        try:\n",
    "            if isinstance(row[col],str) and row[col]!=\"nan\" and row[col]!=\"NaN\":\n",
    "                tags = [tag.replace(\"/\",\" and \") for tag in literal_eval(row[col])]\n",
    "                row[col] = [jargon_map[term] if term in jargon_map else term for tag in tags for term in tag.split()]   \n",
    "        except:\n",
    "            print(f\"error in row {idx}, column {col}\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cosmetic-distributor",
   "metadata": {},
   "source": [
    "# Process data\n",
    "- tokenize\n",
    "- remove non-letters\n",
    "- convert to lowercase\n",
    "- spell-check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expected-objective",
   "metadata": {},
   "outputs": [],
   "source": [
    "spell = Speller()\n",
    "stop_words = np.unique(stopwords.words('english') + [\"the\"])\n",
    "for idx, row in df.iterrows():\n",
    "    for col in cols_to_parse:\n",
    "        try:\n",
    "            if isinstance(row[col],list):\n",
    "                tokens = wordpunct_tokenize(\" \".join([term.lower() for term in row[col]]))\n",
    "                row[col] = [spell(token) for token in tokens if token.isalpha() and token not in stop_words]\n",
    "        except:\n",
    "            print(f\"error in row {idx}, column {col}\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radical-trinity",
   "metadata": {},
   "source": [
    "# Save processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handled-toyota",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/processed_data.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "derived-universal",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
