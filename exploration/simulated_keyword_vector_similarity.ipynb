{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "reported-emphasis",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reverse-rebecca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threatened-willow",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approved-honey",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install random-word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cathedral-filling",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tracked-swing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import jaccard_score\n",
    "from random_word import RandomWords\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agricultural-rebate",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indie-gregory",
   "metadata": {},
   "source": [
    "# Generate fake keyword data\n",
    "- no categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equal-legislation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random keywords\n",
    "rw = RandomWords()\n",
    "rand_keywords = rw.get_random_words()\n",
    "print(rand_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlled-emperor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatize\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemma_keywords = np.array([lemmatizer.lemmatize(k) for k in rand_keywords])\n",
    "print(lemma_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minus-greenhouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users = 100\n",
    "users = [f\"user_{i}\" for i in range(num_users)]\n",
    "num_keywords = 50\n",
    "mean_responses = 15\n",
    "std_responses = 5\n",
    "keywords = lemma_keywords\n",
    "similar_users = [(\"user_0\",\"user_1\"),(\"user_2\",\"user_3\"),(\"user_4\",\"user_5\")]\n",
    "keyword_dict = {k:[] for k in keywords}\n",
    "\n",
    "for user in users:\n",
    "    # copy responses from partnered similar user\n",
    "    sim_user = False\n",
    "    for pair_of_users in similar_users:\n",
    "        if user == pair_of_users[1]:\n",
    "            for k in keywords:\n",
    "                keyword_dict[k].append(keyword_dict[k][-1])\n",
    "            sim_user = True\n",
    "            continue\n",
    "    if sim_user:\n",
    "        continue\n",
    "    \n",
    "    # generate random responses\n",
    "    num_responses = int(np.random.normal(mean_responses,std_responses))\n",
    "    keywords_responded = np.random.choice(keywords,size=num_responses,replace=False)\n",
    "    for k in keywords:\n",
    "        if k in keywords_responded:\n",
    "            keyword_dict[k].append(1)\n",
    "        else:\n",
    "            keyword_dict[k].append(0)\n",
    "\n",
    "keyword_df = pd.DataFrame(keyword_dict,index=users)\n",
    "keyword_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extended-rally",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,6))\n",
    "sns.heatmap(keyword_df,cmap=\"Blues\")\n",
    "plt.title(\"Keyword Responses\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungry-wyoming",
   "metadata": {},
   "source": [
    "# Compute cosine similarity between pairs of users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "junior-friendly",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_arr = keyword_df.to_numpy()\n",
    "keyword_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "material-switch",
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_similarity = cosine_similarity(keyword_arr)\n",
    "cos_similarity.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wound-surface",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,12))\n",
    "sns.heatmap(cos_similarity,cmap=\"Blues\",xticklabels=users,yticklabels=users)\n",
    "plt.title(\"Cosine similarity\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generous-bones",
   "metadata": {},
   "source": [
    "# Jaccard similarity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlling-louisville",
   "metadata": {},
   "outputs": [],
   "source": [
    "jacc_similarity = np.zeros((100,100))\n",
    "for i,user_keywords in enumerate(keyword_arr):\n",
    "    other_users = np.delete(keyword_arr,np.where(users==user)[0],axis=0)\n",
    "    for j,other_user in enumerate(other_users):\n",
    "        jacc_similarity[i,j] = jaccard_score(user_keywords,other_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "furnished-designer",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,12))\n",
    "sns.heatmap(jacc_similarity,cmap=\"Blues\",xticklabels=users,yticklabels=users)\n",
    "plt.title(\"Jaccard similarity\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "later-columbus",
   "metadata": {},
   "source": [
    "# Similarity rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "waiting-entrance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_rankings(users, similarity_scores, num_recs: int=5) -> pd.DataFrame:\n",
    "    user_recs_dict = {\"user\":[],\"recommendation\":[],\"score\":[], \"ranking\":[]}\n",
    "    for i,user in enumerate(users):\n",
    "        # get sim scores and remove current user\n",
    "        curr_sim_scores = np.delete(similarity_scores[i].copy(),i)\n",
    "        curr_users = np.delete(np.array(users.copy()),i)\n",
    "        # get recs\n",
    "        for i in range(num_recs):\n",
    "            user_recs_dict[\"user\"].append(user)\n",
    "            # current most similar user and score\n",
    "            top_sim_idx = np.argmax(curr_sim_scores)\n",
    "            top_sim_user = curr_users[top_sim_idx]\n",
    "            top_sim_score = curr_sim_scores[top_sim_idx]\n",
    "            user_recs_dict[\"recommendation\"].append(top_sim_user)\n",
    "            user_recs_dict[\"score\"].append(top_sim_score)\n",
    "            user_recs_dict[\"ranking\"].append(i+1)\n",
    "            # remove from lists\n",
    "            curr_sim_scores = np.delete(curr_sim_scores,top_sim_idx)\n",
    "            curr_users = np.delete(curr_users,top_sim_idx)\n",
    "\n",
    "    user_recs = pd.DataFrame.from_dict(user_recs_dict)\n",
    "    return user_recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qualified-holder",
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_user_recs = similarity_rankings(users, cos_similarity)\n",
    "rand_users = [\"user_0\",\"user_1\",\"user_2\",\"user_3\",\"user_4\",\"user_5\",\"user_20\",\"user_30\"]\n",
    "fig,axes = plt.subplots(4,2,figsize=(15,10),sharey=True)\n",
    "for i,(user,ax) in enumerate(zip(rand_users,np.ravel(axes))):\n",
    "    curr_user = cos_user_recs[cos_user_recs[\"user\"]==user]\n",
    "    ax.bar(curr_user.recommendation,curr_user.score)\n",
    "    ax.set_title(user)\n",
    "    ax.set_ylabel(\"cosine similarity\") if not i%2 else ax.set_ylabel(\"\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enormous-crime",
   "metadata": {},
   "outputs": [],
   "source": [
    "jacc_user_recs = similarity_rankings(users, jacc_similarity)\n",
    "rand_users = [\"user_0\",\"user_1\",\"user_2\",\"user_3\",\"user_4\",\"user_5\",\"user_20\",\"user_30\"]\n",
    "fig,axes = plt.subplots(4,2,figsize=(15,10),sharey=True)\n",
    "for i,(user,ax) in enumerate(zip(rand_users,np.ravel(axes))):\n",
    "    curr_user = jacc_user_recs[jacc_user_recs[\"user\"]==user]\n",
    "    ax.bar(curr_user.recommendation,curr_user.score)\n",
    "    ax.set_title(user)\n",
    "    ax.set_ylabel(\"jaccard similarity\") if not i%2 else ax.set_ylabel(\"\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elementary-choir",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
