{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "tired-circular",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nominated-grill",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from gensim.models import KeyedVectors\n",
    "import visualization as viz\n",
    "import metrics as met\n",
    "from ast import literal_eval\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intended-segment",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focal-recall",
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_data = pd.read_csv(\"data/processed_data.csv\")\n",
    "proc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dutch-assistant",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = pd.read_csv(\"data/clean_data.csv\")\n",
    "clean_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposite-argument",
   "metadata": {},
   "source": [
    "# Remove users with under a certain number of responses\n",
    "- there must be at least 1 response to each category used in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identical-request",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_to_remove = []\n",
    "cat_response_thresh = 1\n",
    "cols_to_include = [\"Experience\", \"Skills\", \"Interests\", \"Objectives\", \"Stages\"]\n",
    "for idx, row in proc_data.iterrows():\n",
    "    for col in cols_to_include:\n",
    "        if isinstance(row[col],str) and row[col] != \"NaN\" and row[col] != \"nan\":\n",
    "            n_responses = len(literal_eval(row[col]))\n",
    "            if n_responses < cat_response_thresh:\n",
    "                indices_to_remove.append(idx)\n",
    "        else:\n",
    "            indices_to_remove.append(idx)\n",
    "proc_data = proc_data.drop(index=indices_to_remove).reset_index(drop=True)\n",
    "proc_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signal-germany",
   "metadata": {},
   "source": [
    "# Word embedding\n",
    "- Google News Word2Vec\n",
    "- trained on about 100 billion words from Google News\n",
    "- contains 3 million words and phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incoming-extraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KeyedVectors.load_word2vec_format('models/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "later-messenger",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "user = \"Jacob Sheldon\"\n",
    "responses = []\n",
    "cols_to_include = [\"Experience\", \"Skills\", \"Stages\", \"Interests\", \"Objectives\"]\n",
    "for idx, row in proc_data[proc_data[\"Name\"]==user].iterrows():\n",
    "    for col in cols_to_include:\n",
    "        try:\n",
    "            if isinstance(row[col],str) and row[col] != \"NaN\":\n",
    "                responses.extend(literal_eval(row[col]))\n",
    "        except:\n",
    "            user = row[\"Name\"]\n",
    "            print(f\"error in row {idx}, column {col}, user {user}\")\n",
    "\n",
    "embedding = []\n",
    "for word in responses:\n",
    "    try:\n",
    "        embedding.append(model[word])\n",
    "    except:\n",
    "        print(f\"{word} not found in model\")\n",
    "\n",
    "fig = viz.plot_embedding(embedding,responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incomplete-reservation",
   "metadata": {},
   "outputs": [],
   "source": [
    "terms_not_in_model = []\n",
    "user_embeddings = []\n",
    "all_users = proc_data[\"Name\"].tolist()\n",
    "users = proc_data[\"Name\"].tolist()\n",
    "ave_user_embedding = []\n",
    "cols_to_include = [\"Experience\", \"Skills\", \"Interests\", \"Objectives\", \"Stages\"]\n",
    "for idx, row in proc_data.iterrows():\n",
    "    # get all responses\n",
    "    responses = []\n",
    "    for col in cols_to_include:\n",
    "        try:\n",
    "            if isinstance(row[col],str) and row[col] != \"NaN\":\n",
    "                responses.extend(literal_eval(row[col]))\n",
    "        except:\n",
    "            user = row[\"Name\"]\n",
    "            print(f\"error in row {idx}, column {col}, user {user}\")\n",
    "    \n",
    "    if len(responses) == 0:\n",
    "        users.remove(row[\"Name\"])\n",
    "        continue\n",
    "    \n",
    "    # embedding for each word\n",
    "    embedding = []\n",
    "    for resp in responses:\n",
    "        try:\n",
    "            embedding.append(model[resp])\n",
    "        except:\n",
    "            if resp not in terms_not_in_model:\n",
    "                print(f\"{resp} not found in model\")\n",
    "                terms_not_in_model.append(resp)\n",
    "            else:\n",
    "                pass\n",
    "    # fill in nans with zeros\n",
    "    embedding = [np.nan_to_num(word_embed,copy=True,nan=0.0) for word_embed in embedding]\n",
    "    \n",
    "    user_embeddings.append(embedding)\n",
    "    \n",
    "    # average\n",
    "    ave_user_embedding.append(np.nanmean(np.array(embedding),axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "balanced-porter",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = viz.plot_embedding(ave_user_embedding,users,include_labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spanish-antibody",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = viz.plot_embedding(np.array(ave_user_embedding),users,include_labels=False,dim=\"3d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "still-observer",
   "metadata": {},
   "source": [
    "# Similarity rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "general-royal",
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_similarity, similarity_scores = met.compute_similarity_rankings(ave_user_embedding, users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acoustic-union",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,12))\n",
    "sns.heatmap(cos_similarity,cmap=\"Blues\",xticklabels=users,yticklabels=users)\n",
    "plt.title(\"Cosine similarity\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corresponding-satin",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sorted_recs = similarity_scores.sort_values(\"Cosine Similarity\",ascending=False)\n",
    "sorted_recs[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moved-railway",
   "metadata": {},
   "source": [
    "# Visualize top matches across users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frank-bradford",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_users = np.random.choice(users,size=10,replace=False)\n",
    "columns = [\"Experience\", \"Skills\", \"Interests\", \"Objectives\", \"Stages\"]\n",
    "with PdfPages(\"recommendations/GoogleWord2Vec_recommendations.pdf\") as pdf:\n",
    "    for user in rand_users:\n",
    "        # get top rec\n",
    "        top_rec_df = similarity_scores[similarity_scores[\"User1\"]==user].sort_values(\"Ranking\",ascending=True)\n",
    "\n",
    "        # shared features\n",
    "        rec = top_rec_df[\"User2\"].tolist()[0]\n",
    "        score = top_rec_df[\"Cosine Similarity\"].tolist()[0]\n",
    "        fig = viz.compare_users(user, rec, columns, score)\n",
    "        pdf.savefig(fig)\n",
    "        \n",
    "        # locations in embed space\n",
    "        fig = viz.plot_embedding(\n",
    "            ave_user_embedding,\n",
    "            [u if u in [user,rec] else \"\" for u in users],\n",
    "            highlight_labels=True,\n",
    "            xlims=(-0.25,0.5),\n",
    "            ylims=(-0.5,0.5),\n",
    "            figsize=(12,9),\n",
    "            dim=\"3d\"\n",
    "        )\n",
    "        pdf.savefig(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exact-laptop",
   "metadata": {},
   "source": [
    "# Visualize matches for one user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quiet-louis",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = \"Jacob Sheldon\"\n",
    "columns = [\"Experience\", \"Skills\", \"Interests\", \"Objectives\"]\n",
    "rec_df = similarity_scores[similarity_scores[\"User1\"]==user].sort_values(\"Ranking\",ascending=True)\n",
    "with PdfPages(f\"recommendations/GoogleWord2Vec_recommendations_{user}.pdf\") as pdf:\n",
    "    for idx,row in rec_df[:5].iterrows():\n",
    "        # get rec\n",
    "        rec = row[\"User2\"]\n",
    "        score = row[\"Cosine Similarity\"]\n",
    "\n",
    "        # compare features\n",
    "        fig = viz.compare_users(user, rec, columns, score)\n",
    "        pdf.savefig(fig)\n",
    "        \n",
    "        # locations in embed space\n",
    "        fig = viz.plot_embedding(\n",
    "            ave_user_embedding,\n",
    "            [u if u in [user,rec] else \"\" for u in users],\n",
    "            highlight_labels=True,\n",
    "            figsize=(12,9),\n",
    "            dim=\"3d\"\n",
    "        )\n",
    "        pdf.savefig(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certain-peter",
   "metadata": {},
   "source": [
    "# Correlation between similarity metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revised-momentum",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_scores[\"Jaccard Similarity\"] = [0]*len(similarity_scores)\n",
    "for idx,row in similarity_scores.iterrows():\n",
    "    similarity_scores.loc[idx,\"Jaccard Similarity\"] = met.jaccard_similarity(row[\"User1\"],row[\"User2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inner-nightmare",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,6))\n",
    "sns.scatterplot(data=similarity_scores,x=\"Cosine Similarity\",y=\"Jaccard Similarity\")\n",
    "similarity_metrics = similarity_scores.drop(columns=[\"User1\",\"User2\",\"Ranking\"])\n",
    "corr = np.round(similarity_metrics.corr().to_numpy()[0][1],2)\n",
    "plt.title(f\"Correlation -- {corr}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eleven-driving",
   "metadata": {},
   "source": [
    "# Normalize cosine similarity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composed-stamp",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_similarity_scores = similarity_scores.copy()\n",
    "cos_sim_scores = norm_similarity_scores[\"Cosine Similarity\"].tolist()\n",
    "norm_similarity_scores[\"Normalized Cosine Similarity\"] = MinMaxScaler((0,max(cos_sim_scores))).fit_transform(np.array(cos_sim_scores).reshape(-1,1))\n",
    "norm_similarity_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frank-forum",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_similarity_scores.plot(x=\"Cosine Similarity\",y=\"Normalized Cosine Similarity\")\n",
    "plt.ylabel(\"Normalized Cosine Similarity\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "provincial-speaker",
   "metadata": {},
   "source": [
    "# Get top 20 pairs of unique people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atlantic-abuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = []\n",
    "sorted_similarity_scores = norm_similarity_scores.sort_values(\"Ranking\").sort_values(\"Normalized Cosine Similarity\",ascending=False)\n",
    "user_pairs = [(row[\"User1\"],row[\"User2\"],row[\"Normalized Cosine Similarity\"]) for idx,row in sorted_similarity_scores.iterrows()]\n",
    "for u in user_pairs:\n",
    "    if len(pairs) == 20:\n",
    "        break\n",
    "    if np.any([u[0] in p or u[1] in p for p in pairs]):\n",
    "        continue\n",
    "    pairs.append((u[0],u[1],u[2]))\n",
    "pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accurate-pathology",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"Experience\", \"Skills\", \"Interests\", \"Objectives\", \"Stages\"]\n",
    "with PdfPages(\"recommendations/GoogleWord2Vec_recommendations.pdf\") as pdf:\n",
    "    for pair in pairs:\n",
    "        user = pair[0]\n",
    "        rec = pair[1]\n",
    "        score = pair[2]\n",
    "        \n",
    "        # shared features\n",
    "        fig = viz.compare_users(user, rec, columns, score)\n",
    "        pdf.savefig(fig)\n",
    "        \n",
    "        # locations in embed space\n",
    "        fig = viz.plot_embedding(\n",
    "            ave_user_embedding,\n",
    "            [u if u in [user,rec] else \"\" for u in users],\n",
    "            highlight_labels=True,\n",
    "            xlims=(-0.25,0.5),\n",
    "            ylims=(-0.5,0.5),\n",
    "            figsize=(12,9),\n",
    "            dim=\"3d\"\n",
    "        )\n",
    "        pdf.savefig(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fallen-turkish",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_user_pairs = np.hstack([[p[0],p[1]] for p in pairs])\n",
    "print(\"All unique users in chosen pairs:\",len(all_user_pairs)==len(set(all_user_pairs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qualified-portable",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
